---
id: 10
title: Audio Analysis & Visualization
description: Comprehensive tutorials for analyzing audio streams (level, spectrum, VAD) and visualizing data with SoundFlow.
navOrder: 10
category: Tutorials and Examples
---
import { Icon } from "@iconify/react";
import {Tab, Tabs} from "@heroui/react";
import {Steps, Step} from '/src/components/Shared/Steps';

# Audio Analysis & Visualization with SoundFlow

Welcome to the SoundFlow audio analysis and visualization tutorials! This guide will walk you through extracting valuable data from audio streams, such as level information, frequency spectrum, and voice activity, as well as visualizing this data, using the powerful SoundFlow C# audio library.

Whether you're building a custom meter, a real-time spectrum display, or a smart voice assistant, these examples have you covered.

<Tabs color="secondary" variant="underlined" aria-label="Audio Analysis and Visualization tutorials">
    <Tab key="level-metering" title="Level Metering">
        This tutorial demonstrates how to use the `LevelMeterAnalyzer` to measure the RMS and peak levels of an
        audio stream.
        <Steps>
            <Step title="Create & Install" description="Setup project & package"
                  icon='ic:outline-create-new-folder'>
                ### 1. Create a new console application and install SoundFlow:
                ```bash
                dotnet new console -o LevelMetering
                cd LevelMetering
                dotnet add package SoundFlow
                ```
            </Step>
            <Step title="Write Code" description="Implement player with analyzer" icon='ph:code-bold'>
                ### 2. Replace `Program.cs` with the following code:
                ```csharp
                using SoundFlow.Abstracts;
                using SoundFlow.Abstracts.Devices;
                using SoundFlow.Backends.MiniAudio;
                using SoundFlow.Components;
                using SoundFlow.Enums;
                using SoundFlow.Providers;
                using SoundFlow.Structs;
                using SoundFlow.Visualization;
                using System;
                using System.IO;
                using System.Linq;

                namespace LevelMetering;

                internal static class Program
                {
                    private static void Main(string[] args)
                    {
                        // Initialize the audio engine.
                        using var audioEngine = new MiniAudioEngine();
                        
                        var defaultDevice = audioEngine.PlaybackDevices.FirstOrDefault(d => d.IsDefault);
                        if(defaultDevice.Id == IntPtr.Zero)
                        {
                            Console.WriteLine("No default playback device found.");
                            return;
                        }

                        var audioFormat = new AudioFormat
                        {
                            Format = SampleFormat.F32,
                            SampleRate = 48000,
                            Channels = 2
                        };
                        
                        using var device = audioEngine.InitializePlaybackDevice(defaultDevice, audioFormat);
                        
                        // Create a SoundPlayer and load an audio file.
                        using var dataProvider = new StreamDataProvider(audioEngine, audioFormat, File.OpenRead("path/to/your/audiofile.wav"));
                        using var player = new SoundPlayer(audioEngine, audioFormat, dataProvider);

                        // Create a LevelMeterAnalyzer, passing the audio format.
                        var levelMeter = new LevelMeterAnalyzer(audioFormat);

                        // Attach the analyzer to the player.
                        player.AddAnalyzer(levelMeter);

                        // Add the player to the device's master mixer.
                        device.MasterMixer.AddComponent(player);

                        // Start playback.
                        device.Start();
                        player.Play();

                        // Create a timer to periodically display the RMS and peak levels.
                        var timer = new System.Timers.Timer(100); // Update every 100 milliseconds
                        timer.Elapsed += (sender, e) =>
                        {
                            Console.WriteLine($"RMS Level: {levelMeter.Rms:F4}, Peak Level: {levelMeter.Peak:F4}");
                        };
                        timer.Start();

                        // Keep the console application running until the user presses a key.
                        Console.WriteLine("Playing audio and displaying level meter... Press any key to stop.");
                        Console.ReadKey();

                        // Stop playback and clean up.
                        timer.Stop();
                        device.Stop();
                    }
                }
                ```
                ***Replace `"path/to/your/audiofile.wav"` with the actual path to an audio file.***
            </Step>
            <Step title="Run Application" description="Run the app" icon='lucide:play'>
                ### 3. Build and run the application:
                ```bash
                dotnet run
                ```
            </Step>
        </Steps>

        **Explanation:**

        After setting up the `AudioEngine` and initializing an `AudioPlaybackDevice`, a `SoundPlayer` is created. A `LevelMeterAnalyzer` is then instantiated, requiring an `AudioFormat` in its constructor. The analyzer is attached directly to the `player` using `player.AddAnalyzer(levelMeter)`.
        When the `player` processes audio, it automatically passes its audio data to the attached `levelMeter`. A timer then periodically reads the `Rms` and `Peak` properties from the analyzer and displays them in the console, providing a real-time level readout.
    </Tab>

    <Tab key="spectrum-analysis" title="Spectrum Analysis">
        This tutorial demonstrates how to use the `SpectrumAnalyzer` to analyze frequency content using FFT.
        <Steps>
            <Step title="Create & Install" description="Setup project & package"
                  icon='ic:outline-create-new-folder'>
                ### 1. Create a new console application and install SoundFlow:
                ```bash
                dotnet new console -o SpectrumAnalysis
                cd SpectrumAnalysis
                dotnet add package SoundFlow
                ```
            </Step>
            <Step title="Write Code" description="Implement player with analyzer" icon='ph:code-bold'>
                ### 2. Replace `Program.cs` with the following code:
                ```csharp
                using SoundFlow.Abstracts;
                using SoundFlow.Abstracts.Devices;
                using SoundFlow.Backends.MiniAudio;
                using SoundFlow.Components;
                using SoundFlow.Enums;
                using SoundFlow.Providers;
                using SoundFlow.Structs;
                using SoundFlow.Visualization;
                using System;
                using System.IO;
                using System.Linq;

                namespace SpectrumAnalysis;

                internal static class Program
                {
                    private static void Main(string[] args)
                    {
                        // Initialize the audio engine.
                        using var audioEngine = new MiniAudioEngine();
                        
                        var defaultDevice = audioEngine.PlaybackDevices.FirstOrDefault(d => d.IsDefault);
                        if (defaultDevice.Id == IntPtr.Zero)
                        {
                            Console.WriteLine("No default playback device found.");
                            return;
                        }

                        var audioFormat = new AudioFormat
                        {
                            Format = SampleFormat.F32,
                            SampleRate = 48000,
                            Channels = 2
                        };
                        
                        using var device = audioEngine.InitializePlaybackDevice(defaultDevice, audioFormat);
                        
                        // Create a SoundPlayer and load an audio file.
                        using var dataProvider = new StreamDataProvider(audioEngine, audioFormat, File.OpenRead("path/to/your/audiofile.wav"));
                        using var player = new SoundPlayer(audioEngine, audioFormat, dataProvider);

                        // Create a SpectrumAnalyzer with an FFT size of 2048.
                        var spectrumAnalyzer = new SpectrumAnalyzer(audioFormat, fftSize: 2048);

                        // Attach the spectrum analyzer to the player.
                        player.AddAnalyzer(spectrumAnalyzer);

                        // Add the player to the device's master mixer.
                        device.MasterMixer.AddComponent(player);

                        // Start playback.
                        device.Start();
                        player.Play();

                        // Create a timer to periodically display the spectrum data.
                        var timer = new System.Timers.Timer(100); // Update every 100 milliseconds
                        timer.Elapsed += (sender, e) =>
                        {
                            // Get the spectrum data from the analyzer.
                            var spectrumData = spectrumAnalyzer.SpectrumData;

                            // Print the magnitude of the first few frequency bins.
                            if (spectrumData.Length > 0)
                            {
                                Console.Write("Spectrum: ");
                                for (int i = 0; i < Math.Min(10, spectrumData.Length); i++)
                                {
                                    Console.Write($"{spectrumData[i]:F2} ");
                                }
                                Console.WriteLine();
                            }
                        };
                        timer.Start();

                        // Keep the console application running until the user presses a key.
                        Console.WriteLine("Playing audio and displaying spectrum data... Press any key to stop.");
                        Console.ReadKey();

                        // Stop playback and clean up.
                        timer.Stop();
                        device.Stop();
                    }
                }
                ```
                ***Replace `"path/to/your/audiofile.wav"` with the actual path to an audio file.***
            </Step>
            <Step title="Run Application" description="Run the app" icon='lucide:play'>
                ### 3. Build and run the application:
                ```bash
                dotnet run
                ```
            </Step>
        </Steps>

        **Explanation:**

        This code follows a similar pattern to level metering. A `SpectrumAnalyzer` is created, requiring the `audioFormat` and an `fftSize` (which must be a power of two). It is then attached to the `player` using `AddAnalyzer`. As the `player` processes audio, it feeds the data to the `spectrumAnalyzer`, which performs a Fast Fourier Transform (FFT).
        A timer periodically accesses the `spectrumAnalyzer.SpectrumData` property, which contains the magnitudes of the frequency bins, and prints the first few values to the console for a simple real-time display of the frequency content.
    </Tab>

    <Tab key="vad" title="Voice Activity Detection">
        This tutorial demonstrates how to use the `VoiceActivityDetector` to detect the presence of human voice.
        <Steps>
            <Step title="Create & Install" description="Setup project & package"
                  icon='ic:outline-create-new-folder'>
                ### 1. Create a new console application and install SoundFlow:
                ```bash
                dotnet new console -o VoiceActivityDetection
                cd VoiceActivityDetection
                dotnet add package SoundFlow
                ```
            </Step>
            <Step title="Write Code" description="Implement VAD on a source" icon='ph:code-bold'>
                ### 2. Replace `Program.cs` with the following code:
                ```csharp
                using SoundFlow.Abstracts;
                using SoundFlow.Abstracts.Devices;
                using SoundFlow.Backends.MiniAudio;
                using SoundFlow.Components;
                using SoundFlow.Enums;
                using SoundFlow.Providers;
                using SoundFlow.Structs;
                using System;
                using System.IO;
                using System.Linq;

                namespace VoiceActivityDetection;

                internal static class Program
                {
                    private static void Main(string[] args)
                    {
                        // Initialize the audio engine.
                        using var audioEngine = new MiniAudioEngine();
                        
                        var defaultDevice = audioEngine.PlaybackDevices.FirstOrDefault(d => d.IsDefault);
                        if (defaultDevice.Id == IntPtr.Zero)
                        {
                            Console.WriteLine("No default playback device found.");
                            return;
                        }

                        var audioFormat = new AudioFormat
                        {
                            Format = SampleFormat.F32,
                            SampleRate = 48000,
                            Channels = 2
                        };
                        
                        using var device = audioEngine.InitializePlaybackDevice(defaultDevice, audioFormat);
                        
                        // Create a SoundPlayer and load an audio file with speech.
                        using var dataProvider = new StreamDataProvider(audioEngine, audioFormat, File.OpenRead("path/to/your/speechfile.wav"));
                        using var player = new SoundPlayer(audioEngine, audioFormat, dataProvider);

                        // Create a VoiceActivityDetector.
                        var vad = new VoiceActivityDetector(audioFormat);

                        // Attach the VAD as an analyzer to the player's output.
                        player.AddAnalyzer(vad);

                        // Subscribe to the SpeechDetected event.
                        vad.SpeechDetected += isDetected => Console.WriteLine($"Speech detected: {isDetected}");

                        // Add the player to the device's master mixer.
                        device.MasterMixer.AddComponent(player);
                        
                        // Start playback.
                        device.Start();
                        player.Play();

                        // Keep the console application running until the user presses a key.
                        Console.WriteLine("Analyzing audio for voice activity... Press any key to stop.");
                        Console.ReadKey();
                        
                        device.Stop();
                    }
                }
                ```
                ***Replace `"path/to/your/speechfile.wav"` with the path to an audio file containing speech.***
            </Step>
            <Step title="Run Application" description="Run the app" icon='lucide:play'>
                ### 3. Build and run the application:
                ```bash
                dotnet run
                ```
            </Step>
        </Steps>

        **Explanation:**

        This code demonstrates how to detect voice in an audio stream. After initializing the `AudioEngine`, `AudioPlaybackDevice`, and `SoundPlayer`, a `VoiceActivityDetector` is created, passing the `audioFormat` to its constructor. It is then attached to the `player` with `AddAnalyzer`.
        The key part of this example is subscribing to the `vad.SpeechDetected` event. This event fires whenever the VAD's state changes (from silence to speech, or vice versa), providing a boolean value. The event handler simply prints the new state to the console. This event-driven approach is efficient for building applications that need to react to the presence or absence of speech.
    </Tab>

    <Tab key="level-meter-viz" title="Console Level Meter">
        Demonstrates creating a console-based level meter using the `LevelMeterAnalyzer` and
        `LevelMeterVisualizer`.
        <Steps>
            <Step title="Create & Install" description="Setup project & package"
                  icon='ic:outline-create-new-folder'>
                ### 1. Create a new console application and install SoundFlow:
                ```bash
                dotnet new console -o LevelMeterVisualization
                cd LevelMeterVisualization
                dotnet add package SoundFlow
                ```
            </Step>
            <Step title="Write Code" description="Implement player with visualizer" icon='ph:code-bold'>
                ### 2. Replace `Program.cs` with the following code:
                ```csharp
                using SoundFlow.Abstracts;
                using SoundFlow.Abstracts.Devices;
                using SoundFlow.Backends.MiniAudio;
                using SoundFlow.Components;
                using SoundFlow.Enums;
                using SoundFlow.Interfaces;
                using SoundFlow.Providers;
                using SoundFlow.Structs;
                using SoundFlow.Visualization;
                using System;
                using System.IO;
                using System.Linq;

                namespace LevelMeterVisualization;

                internal static class Program
                {
                    private static void Main(string[] args)
                    {
                        // Standard engine and device setup.
                        using var audioEngine = new MiniAudioEngine();
                        var defaultDevice = audioEngine.PlaybackDevices.FirstOrDefault(d => d.IsDefault);
                        if(defaultDevice.Id == IntPtr.Zero) return;
                        var audioFormat = new AudioFormat { Format = SampleFormat.F32, SampleRate = 48000, Channels = 2 };
                        using var device = audioEngine.InitializePlaybackDevice(defaultDevice, audioFormat);
                        
                        // Create a player for an audio file.
                        using var dataProvider = new StreamDataProvider(audioEngine, audioFormat, File.OpenRead("path/to/your/audiofile.wav"));
                        using var player = new SoundPlayer(audioEngine, audioFormat, dataProvider);

                        // Create the LevelMeterAnalyzer and LevelMeterVisualizer.
                        // The visualizer is linked to the analyzer.
                        var levelMeterAnalyzer = new LevelMeterAnalyzer(audioFormat);
                        var levelMeterVisualizer = new LevelMeterVisualizer(levelMeterAnalyzer);
                        
                        // Attach the analyzer to the player. The analyzer will automatically
                        // pass its data to the linked visualizer.
                        player.AddAnalyzer(levelMeterAnalyzer);

                        // Add the player to the mixer.
                        device.MasterMixer.AddComponent(player);
                        
                        // Start playback.
                        device.Start();
                        player.Play();

                        // Subscribe to the VisualizationUpdated event to trigger a redraw.
                        levelMeterVisualizer.VisualizationUpdated += (sender, e) =>
                        {
                            DrawLevelMeter(levelMeterAnalyzer.Rms, levelMeterAnalyzer.Peak);
                        };

                        // Start a timer to update the visualization.
                        var timer = new System.Timers.Timer(1000 / 60); // Update at approximately 60 FPS
                        timer.Elapsed += (sender, e) =>
                        {
                            levelMeterVisualizer.ProcessOnAudioData(System.Array.Empty<float>());
                            levelMeterVisualizer.Render(new ConsoleVisualizationContext());
                        };
                        timer.Start();

                        // Keep the console application running until the user presses a key.
                        Console.WriteLine("Playing audio and displaying level meter... Press any key to stop.");
                        Console.ReadKey();

                        device.Stop();
                        levelMeterVisualizer.Dispose();
                    }

                    // Helper method to draw a simple console-based level meter.
                    private static void DrawLevelMeter(float rms, float peak)
                    {
                        int barLength = (int)(rms * 40); 
                        int peakMarkerPos = (int)(peak * 40);

                        Console.SetCursorPosition(0, 0);
                        Console.Write("RMS:  [");
                        Console.Write(new string('#', barLength));
                        Console.Write(new string(' ', 40 - barLength));
                        Console.Write("]\n");

                        Console.SetCursorPosition(0, 1);
                        Console.Write("Peak: [");
                        Console.Write(new string(' ', 40));
                        Console.Write("]\r"); // Carriage return to move back
                        Console.Write("Peak: [");
                        if(peakMarkerPos < 40) Console.SetCursorPosition(7 + peakMarkerPos, 1);
                        Console.Write("|");
                        
                        Console.SetCursorPosition(0, 3);
                    }
                }

                // Simple IVisualizationContext implementation for console output.
                public class ConsoleVisualizationContext : IVisualizationContext
                {
                    public void Clear() { }
                    public void DrawLine(float x1, float y1, float x2, float y2, Color color, float thickness = 1) { }
                    public void DrawRectangle(float x, float y, float width, float height, Color color) { }
                }
                ```
                ***Replace `"path/to/your/audiofile.wav"` with the actual path to an audio file.***
            </Step>
            <Step title="Run Application" description="Run the app" icon='lucide:play'>
                ### 3. Build and run the application:
                ```bash
                dotnet run
                ```
            </Step>
        </Steps>

        **Explanation:**

        This example demonstrates the analyzer-visualizer pattern. A `LevelMeterAnalyzer` is created to process the audio, and a `LevelMeterVisualizer` is created, linked to the analyzer. When `player.AddAnalyzer(levelMeterAnalyzer)` is called, the analyzer is attached to the player's audio stream. Inside its processing logic, the analyzer automatically calls its linked visualizer's `ProcessOnAudioData` method.
        We subscribe to the `levelMeterVisualizer.VisualizationUpdated` event, which is fired by the visualizer whenever it receives new data. The event handler calls our `DrawLevelMeter` helper function to render a simple text-based meter in the console, providing a direct visual representation of the audio levels calculated by the analyzer.
    </Tab>

    <Tab key="waveform-viz" title="Console Waveform">
        Demonstrates using `WaveformVisualizer` to display an audio waveform.
        <Steps>
            <Step title="Create & Install" description="Setup project & package"
                  icon='ic:outline-create-new-folder'>
                ### 1. Create a new console application and install SoundFlow:
                ```bash
                dotnet new console -o WaveformVisualization
                cd WaveformVisualization
                dotnet add package SoundFlow
                ```
            </Step>
            <Step title="Write Code" description="Implement waveform visualizer" icon='ph:code-bold'>
                ### 2. Replace `Program.cs` with the following code:
                ```csharp
                using SoundFlow.Abstracts;
                using SoundFlow.Abstracts.Devices;
                using SoundFlow.Backends.MiniAudio;
                using SoundFlow.Components;
                using SoundFlow.Enums;
                using SoundFlow.Providers;
                using SoundFlow.Structs;
                using SoundFlow.Visualization;
                using System;
                using System.Collections.Generic;
                using System.IO;
                using System.Linq;

                namespace WaveformVisualization;

                internal static class Program
                {
                    private static void Main(string[] args)
                    {
                        // Standard setup
                        using var audioEngine = new MiniAudioEngine();
                        var defaultDevice = audioEngine.PlaybackDevices.FirstOrDefault(d => d.IsDefault);
                        if(defaultDevice.Id == IntPtr.Zero) return;
                        var audioFormat = new AudioFormat { Format = SampleFormat.F32, SampleRate = 48000, Channels = 2 };
                        using var device = audioEngine.InitializePlaybackDevice(defaultDevice, audioFormat);
                        
                        using var dataProvider = new StreamDataProvider(audioEngine, audioFormat, File.OpenRead("path/to/your/audiofile.wav"));
                        using var player = new SoundPlayer(audioEngine, audioFormat, dataProvider);

                        // Create a LevelMeterAnalyzer or any analyzer you want.
                        var levelMeterAnalyzer = new LevelMeterAnalyzer();

                        // Create a WaveformVisualizer.
                        var waveformVisualizer = new WaveformVisualizer();

                        // Add the player to the master mixer.
                        Mixer.Master.AddComponent(player);

                        // Subscribe to the VisualizationUpdated event to trigger a redraw.
                        waveformVisualizer.VisualizationUpdated += (sender, e) =>
                        {
                            DrawWaveform(waveformVisualizer.Waveform);
                        };

                        // Connect the player's output to the level meter analyzer's input.
                        player.AddAnalyzer(levelMeterAnalyzer);

                        // Add the player to the master mixer.
                        Mixer.Master.AddComponent(player);

                        // Start playback.
                        player.Play();

                        // Start a timer to update the visualization.
                        var timer = new System.Timers.Timer(1000 / 60); // Update at approximately 60 FPS
                        timer.Elapsed += (sender, e) =>
                        {
                            waveformVisualizer.Render(new ConsoleVisualizationContext()); // ConsoleVisualizationContext is just a placeholder
                        };
                        timer.Start();

                        device.MasterMixer.AddComponent(player);
                        
                        device.Start();
                        player.Play();

                        Console.WriteLine("Playing audio and displaying waveform... Press any key to stop.");
                        Console.ReadKey();

                        device.Stop();
                        waveformVisualizer.Dispose();
                    }

                    // Helper method to draw a simple console-based waveform.
                    private static void DrawWaveform(IReadOnlyList<float> waveform)
                    {
                        Console.Clear();
                        int consoleWidth = Console.WindowWidth;
                        int consoleHeight = Console.WindowHeight;

                        if (waveform.Count == 0) return;

                        for (int i = 0; i < consoleWidth; i++)
                        {
                            int waveformIndex = (int)(i * (waveform.Count / (float)consoleWidth));
                            waveformIndex = Math.Clamp(waveformIndex, 0, waveform.Count - 1);

                            float sampleValue = waveform[waveformIndex];
                            int consoleY = (int)((sampleValue + 1) * 0.5 * (consoleHeight - 1));
                            consoleY = Math.Clamp(consoleY, 0, consoleHeight - 1);

                            if (i < consoleWidth && (consoleHeight - consoleY - 1) < consoleHeight)
                            {
                                Console.SetCursorPosition(i, consoleHeight - consoleY - 1);
                                Console.Write("*");
                            }
                        }
                        Console.SetCursorPosition(0, consoleHeight - 1);
                    }
                }
                ```
                ***Replace `"path/to/your/audiofile.wav"` with the actual path to an audio file.***
            </Step>
            <Step title="Run Application" description="Run the app" icon='lucide:play'>
                ### 3. Build and run the application:
                ```bash
                dotnet run
                ```
            </Step>
        </Steps>

        **Explanation:**

        In this example, the `WaveformVisualizer` is used to directly visualize the audio samples. While it implements `IVisualizer`, it doesn't need a separate `AudioAnalyzer`. It is attached directly to the `player` using `AddAnalyzer`. When the player processes its audio buffer, it passes a copy of that buffer to the `WaveformVisualizer`, which stores it.
        We subscribe to the `VisualizationUpdated` event, which the visualizer raises after receiving a new buffer. The event handler calls `DrawWaveform` to render a simple ASCII representation of the waveform to the console, providing a real-time oscilloscope-like view of the audio signal.
    </Tab>

    <Tab key="spectrum-viz" title="Console Spectrum">
        Demonstrates creating a console-based spectrum analyzer using the `SpectrumAnalyzer` and
        `SpectrumVisualizer`.
        <Steps>
            <Step title="Create & Install" description="Setup project & package"
                  icon='ic:outline-create-new-folder'>
                ### 1. Create a new console application and install SoundFlow:
                ```bash
                dotnet new console -o SpectrumAnalyzerVisualization
                cd SpectrumAnalyzerVisualization
                dotnet add package SoundFlow
                ```
            </Step>
            <Step title="Write Code" description="Implement spectrum visualizer" icon='ph:code-bold'>
                ### 2. Replace `Program.cs` with the following code:
                ```csharp
                using SoundFlow.Abstracts;
                using SoundFlow.Abstracts.Devices;
                using SoundFlow.Backends.MiniAudio;
                using SoundFlow.Components;
                using SoundFlow.Enums;
                using SoundFlow.Interfaces;
                using SoundFlow.Providers;
                using SoundFlow.Structs;
                using SoundFlow.Visualization;
                using System;
                using System.IO;
                using System.Linq;

                namespace SpectrumAnalyzerVisualization;

                internal static class Program
                {
                    private static void Main(string[] args)
                    {
                        // Standard setup.
                        using var audioEngine = new MiniAudioEngine();
                        var defaultDevice = audioEngine.PlaybackDevices.FirstOrDefault(d => d.IsDefault);
                        if(defaultDevice.Id == IntPtr.Zero) return;
                        var audioFormat = new AudioFormat { Format = SampleFormat.F32, SampleRate = 48000, Channels = 2 };
                        using var device = audioEngine.InitializePlaybackDevice(defaultDevice, audioFormat);
                        
                        using var dataProvider = new StreamDataProvider(audioEngine, audioFormat, File.OpenRead("path/to/your/audiofile.wav"));
                        using var player = new SoundPlayer(audioEngine, audioFormat, dataProvider);

                        // Create the SpectrumAnalyzer and SpectrumVisualizer.
                        var spectrumAnalyzer = new SpectrumAnalyzer(audioFormat, fftSize: 2048);
                        var spectrumVisualizer = new SpectrumVisualizer(spectrumAnalyzer);

                        // Attach the analyzer to the player.
                        player.AddAnalyzer(spectrumAnalyzer);
                        
                        device.MasterMixer.AddComponent(player);
                        
                        device.Start();
                        player.Play();

                        // Subscribe to the VisualizationUpdated event to trigger a redraw.
                        spectrumVisualizer.VisualizationUpdated += (sender, e) =>
                        {
                            DrawSpectrum(spectrumAnalyzer.SpectrumData);
                        };

                        // Start a timer to update the visualization.
                        var timer = new System.Timers.Timer(1000 / 60); // Update at approximately 60 FPS
                        timer.Elapsed += (sender, e) =>
                        {
                            spectrumVisualizer.ProcessOnAudioData(Array.Empty<float>());
                            spectrumVisualizer.Render(new ConsoleVisualizationContext());
                        };
                        timer.Start();

                        // Keep the console application running until the user presses a key.
                        Console.WriteLine("Playing audio and displaying spectrum analyzer... Press any key to stop.");
                        Console.ReadKey();

                        device.Stop();
                        spectrumVisualizer.Dispose();
                    }

                    // Helper method to draw a simple console-based spectrum analyzer.
                    private static void DrawSpectrum(ReadOnlySpan<float> spectrumData)
                    {
                        Console.Clear();
                        int consoleWidth = Console.WindowWidth;
                        int consoleHeight = Console.WindowHeight -1;

                        if (spectrumData.IsEmpty) return;

                        for (int i = 0; i < consoleWidth; i++)
                        {
                            // Logarithmic mapping of frequency bins to console columns for better visualization
                            double logIndex = Math.Log10(1 + 9 * ((double)i / consoleWidth));
                            int spectrumIndex = (int)(logIndex * (spectrumData.Length - 1));
                            
                            float magnitude = spectrumData[spectrumIndex];
                            int barHeight = (int)(magnitude * consoleHeight);
                            barHeight = Math.Clamp(barHeight, 0, consoleHeight);

                            for (int j = 0; j < barHeight; j++)
                            {
                                Console.SetCursorPosition(i, consoleHeight - 1 - j);
                                Console.Write("█");
                            }
                        }
                        Console.SetCursorPosition(0, consoleHeight - 1);
                    }
                }

                // Simple IVisualizationContext implementation for console output.
                public class ConsoleVisualizationContext : IVisualizationContext
                {
                    public void Clear() { }
                    public void DrawLine(float x1, float y1, float x2, float y2, Color color, float thickness = 1f) { }
                    public void DrawRectangle(float x, float y, float width, float height, Color color) { }
                }
                ```
                ***Replace `"path/to/your/audiofile.wav"` with the actual path to an audio file.***
            </Step>
            <Step title="Run Application" description="Run the app" icon='lucide:play'>
                ### 3. Build and run the application:
                ```bash
                dotnet run
                ```
            </Step>
        </Steps>

        **Explanation:**

        This code demonstrates the analyzer-visualizer pattern for frequency analysis. A `SpectrumAnalyzer` is created to perform the FFT, and a `SpectrumVisualizer` is linked to it. The analyzer is attached to the `player`, which feeds it audio data. The analyzer processes this data and automatically informs the visualizer.
        We subscribe to the `spectrumVisualizer.VisualizationUpdated` event. In the handler, `DrawSpectrum` is called, which reads the `spectrumAnalyzer.SpectrumData` and renders a simple bar chart of the frequency magnitudes to the console. The drawing logic uses a logarithmic scale for the frequency axis, which provides a more musically intuitive display of the spectrum.
    </Tab>
	
	<Tab key="ui-integration" title={<div className="flex items-center gap-2">
		<Icon icon="lucide:layout-template"/><span>UI Integration</span></div>}>
        These examples use basic console output for simplicity. To integrate SoundFlow's visualizers with a GUI
        framework (like WPF, WinForms, Avalonia, or MAUI), you'll need to:
        <Steps layout='vertical'>
            <Step title="Implement IVisualizationContext" description="Wrap your UI framework's drawing primitives"
                  icon='material-symbols:draw-outline'>
                This class will wrap the drawing primitives of your chosen UI framework. For example, in WPF, you might
                use `DrawingContext` methods to draw shapes on a `Canvas`.
            </Step>
            <Step title="Update UI from Event" description="Trigger a redraw on the UI thread" icon='mdi:update'>
                In the `VisualizationUpdated` event handler, trigger a redraw of your UI element that hosts the
                visualization. Make sure to marshal the update to the UI thread using `Dispatcher.Invoke` or a similar
                mechanism if the event is raised from a different thread.
            </Step>
            <Step title="Call Render Method" description="Pass your context to the visualizer" icon='lucide:render'>
                In your UI's rendering logic, call the `Render` method of the visualizer, passing your
                `IVisualizationContext` implementation.
            </Step>
        </Steps>

        **Example (Conceptual WPF):**

        ```csharp
        // In your XAML:
        // <Canvas x:Name="VisualizationCanvas"/>

        // In your code-behind:
        public partial class MainWindow : Window
        {
            private readonly WaveformVisualizer _visualizer;

            public MainWindow()
            {
                InitializeComponent();

                // ... Initialize AudioEngine, SoundPlayer, etc. ...

                _visualizer = new WaveformVisualizer();
                _visualizer.VisualizationUpdated += OnVisualizationUpdated;

                // ...
            }

            private void OnVisualizationUpdated(object? sender, EventArgs e)
            {
                // Marshal the update to the UI thread
                Dispatcher.Invoke(() =>
                {
                    VisualizationCanvas.Children.Clear(); // Clear previous drawing

                    // Create a custom IVisualizationContext that wraps the Canvas
                    var context = new WpfVisualizationContext(VisualizationCanvas);

                    // Render the visualization
                    _visualizer.Render(context);
                });
            }

            // ...
        }

        // IVisualizationContext implementation for WPF
        public class WpfVisualizationContext : IVisualizationContext
        {
            private readonly Canvas _canvas;

            public WpfVisualizationContext(Canvas canvas)
            {
                _canvas = canvas;
            }

            public void Clear()
            {
                _canvas.Children.Clear();
            }

            public void DrawLine(float x1, float y1, float x2, float y2, SoundFlow.Interfaces.Color color, float thickness = 1f)
            {
                var line = new Line
                {
                    X1 = x1,
                    Y1 = y1,
                    X2 = x2,
                    Y2 = y2,
                    Stroke = new SolidColorBrush(System.Windows.Media.Color.FromArgb((byte)(color.A * 255), (byte)(color.R * 255), (byte)(color.G * 255), (byte)(color.B * 255))),
                    StrokeThickness = thickness
                };
                _canvas.Children.Add(line);
            }

            public void DrawRectangle(float x, float y, float width, float height, SoundFlow.Interfaces.Color color)
            {
                var rect = new Rectangle
                {
                    Width = width,
                    Height = height,
                    Fill = new SolidColorBrush(System.Windows.Media.Color.FromArgb((byte)(color.A * 255), (byte)(color.R * 255), (byte)(color.G * 255), (byte)(color.B * 255)))
                };
                Canvas.SetLeft(rect, x);
                Canvas.SetTop(rect, y);
                _canvas.Children.Add(rect);
            }
        }
        ```

        Remember to adapt this conceptual example to your specific UI framework and project structure.
    </Tab>
</Tabs>

We hope these tutorials have provided a solid foundation for audio analysis and visualization with SoundFlow!